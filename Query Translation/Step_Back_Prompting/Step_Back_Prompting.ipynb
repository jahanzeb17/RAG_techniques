{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGo16KFMxek2",
        "outputId": "d2e20a52-e3d3-4cc0-f03f-21f72c6e4e10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/2.8 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain langchain-nvidia-ai-endpoints duckduckgo-search langchain-groq langchain-community langchain-core chromadb pypdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from google.colab import userdata\n",
        "os.environ['NVIDIA_API_KEY'] = userdata.get('NVIDIA_API_KEY')\n",
        "os.environ['GROQ_API_KEY'] = userdata.get('GROQ_API_KEY')\n",
        "# os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "hn1P-qbByN-X"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Required libraries\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.utilities import DuckDuckGoSearchAPIWrapper"
      ],
      "metadata": {
        "id": "LankG1cvyUOw"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Few Shot Examples\n",
        "examples = [\n",
        "\n",
        "    {\n",
        "        \"input\": \"What is the birthplace of Albert Einstein?\",\n",
        "        \"output\": \"what is Albert Einstein's personal history?\",\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"Can a Tesla car drive itself?\",\n",
        "        \"output\": \"what can a Tesla car do?\",\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"Did Queen Elizabeth II ever visit Canada?\",\n",
        "        \"output\": \"what is Queen Elizabeth II's travel history?\",\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"Can a SpaceX rocket land itself?\",\n",
        "        \"output\": \"what can a SpaceX rocket do?\",\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "NgmcYTryzDwY"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We now transform these to example messages\n",
        "example_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        ('human','{input}'),\n",
        "        ('ai','{output}')\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "-SAc9zY4zXs6"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using few shot prompt template\n",
        "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
        "    example_prompt=example_prompt,\n",
        "    examples=examples\n",
        ")"
      ],
      "metadata": {
        "id": "8HWCiVLpz1ZV"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt\n",
        "system = \"\"\"You are expert at world knowledge. your task is to step back paraphrase question to a more genric step-back question, which is easier to answer. Here are few examples.\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "      ('system',system),\n",
        "      few_shot_prompt,\n",
        "      ('user','{question}')\n",
        "\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "B3NrhkbL0Rmk"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# llm model\n",
        "# llm = ChatNVIDIA(model='google/gemma-2-9b-it')\n",
        "llm = ChatGroq(model_name='llama-3.1-70b-versatile')\n",
        "\n",
        "question_gen = prompt | llm | StrOutputParser()"
      ],
      "metadata": {
        "id": "LB5nIATE4xi9"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"was chatgpt around while trump was president?\"\n",
        "\n",
        "question_gen.invoke({\"question\": question})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "eQsFiGYmrpQo",
        "outputId": "9354ed74-1e50-4bed-c9b7-e8d7d556bb9e"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'when was ChatGPT developed?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "search = DuckDuckGoSearchAPIWrapper(max_results=4)\n",
        "\n",
        "def retriever(query):\n",
        "  return search.run(query=query)"
      ],
      "metadata": {
        "id": "xB2sWyXTq4KO"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Response prompt\n",
        "template = \"\"\"You are an expert of world knowledge. I am going to ask you a question. Your response should be comprehensive and not contradicted with the following context if they are relevant. Otherwise, ignore them if they are not relevant.\n",
        "{normal_context}\n",
        "{step_back_context}\n",
        "\n",
        "Original question: {question}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "response_prompt = ChatPromptTemplate.from_template(template)"
      ],
      "metadata": {
        "id": "FDtnQL005pP8"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = ({\n",
        "    \"normal_context\": RunnableLambda(lambda x: x['question']) | retriever,\n",
        "    \"step_back_context\": question_gen | retriever,\n",
        "    \"question\": lambda x: x[\"question\"]\n",
        "          }\n",
        "         | response_prompt\n",
        "         | llm\n",
        "         | StrOutputParser()\n",
        "    )"
      ],
      "metadata": {
        "id": "M9oKpJeb6ePu"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"was chatgpt around while trump was president?\"\n",
        "\n",
        "chain.invoke({\"question\": question})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "0TdmpnNntA4S",
        "outputId": "305d6071-6377-4383-ced6-fa09de975f36"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Based on the provided context, ChatGPT was not available during Donald Trump's presidency. According to the given information, ChatGPT was released on November 30, 2022, and Donald Trump's presidency ended on January 20, 2021. Therefore, there was a nearly two-year gap between the end of Trump's presidency and the release of ChatGPT.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question2 = 'how to learn ML prepare a roadmap'\n",
        "\n",
        "chain.invoke({\"question\": question2})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "id": "6tr7znoEvl4L",
        "outputId": "4d9d4a25-e544-414a-afaa-eb2a8d9a2670"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"To learn Machine Learning (ML) from scratch, I've prepared a comprehensive roadmap to guide you through the process. This roadmap will cover the essential steps, skills, and resources needed to become proficient in ML.\\n\\n**Phase 1: Foundational Courses (3-6 months)**\\n\\n1. **Mathematics**:\\n\\t* Linear Algebra: Understand vectors, matrices, and operations.\\n\\t* Calculus: Familiarize yourself with derivatives and optimization techniques.\\n\\t* Probability and Statistics: Study probability distributions, Bayes' theorem, and statistical inference.\\n\\t* Resources: Khan Academy, MIT OpenCourseWare, and Coursera.\\n2. **Programming**:\\n\\t* Python: Focus on Python 3.x, as it's the primary language used in ML.\\n\\t* Familiarize yourself with popular libraries: NumPy, pandas, and scikit-learn.\\n\\t* Practice with projects on platforms like LeetCode, HackerRank, or Codewars.\\n3. **Data Structures and Algorithms**:\\n\\t* Study data structures: arrays, linked lists, stacks, queues, trees, and graphs.\\n\\t* Learn algorithms: sorting, searching, graph traversal, and dynamic programming.\\n\\t* Resources: LeetCode, GeeksforGeeks, and Coursera.\\n\\n**Phase 2: Machine Learning Basics (3-6 months)**\\n\\n1. **Machine Learning Fundamentals**:\\n\\t* Study supervised, unsupervised, and reinforcement learning.\\n\\t* Understand key algorithms: linear regression, logistic regression, decision trees, and clustering.\\n\\t* Learn model evaluation metrics and techniques: cross-validation, precision, recall, and F1-score.\\n\\t* Resources: Andrew Ng's Machine Learning course, Coursera, and edX.\\n2. **Python Libraries and Frameworks**:\\n\\t* Scikit-learn: Learn the library's API and how to implement ML algorithms.\\n\\t* TensorFlow or PyTorch: Study one of these popular deep learning frameworks.\\n\\t* Keras: Familiarize yourself with this high-level neural networks API.\\n3. **Projects and Practice**:\\n\\t* Implement ML algorithms from scratch.\\n\\t* Work on projects that involve data preprocessing, feature engineering, and model deployment.\\n\\t* Participate in Kaggle competitions or use public datasets to practice.\\n\\n**Phase 3: Specialized Areas (6-12 months)**\\n\\n1. **Deep Learning**:\\n\\t* Study convolutional neural networks (CNNs), recurrent neural networks (RNNs), and long short-term memory (LSTM) networks.\\n\\t* Learn about transfer learning, fine-tuning, and hyperparameter tuning.\\n\\t* Resources: Stanford CS231n, Coursera, and edX.\\n2. **Natural Language Processing (NLP)**:\\n\\t* Study text preprocessing, tokenization, and word embeddings.\\n\\t* Learn about NLP algorithms: sentiment analysis, named entity recognition, and machine translation.\\n\\t* Resources: Stanford CS224d, Coursera, and edX.\\n3. **Other Specialized Areas**:\\n\\t* Computer Vision: Study image processing, object detection, and segmentation.\\n\\t* Reinforcement Learning: Learn about Q-learning, policy gradients, and actor-critic methods.\\n\\n**Phase 4: Advanced Topics and Industry Applications (6-12 months)**\\n\\n1. **Advanced ML Topics**:\\n\\t* Study ensemble methods, gradient boosting, and random forests.\\n\\t* Learn about attention mechanisms, transformers, and generative models.\\n\\t* Resources: Research papers, conferences, and workshops.\\n2. **Industry Applications**:\\n\\t* Study the application of ML in various industries: healthcare, finance, marketing, and more.\\n\\t* Learn about the challenges, opportunities, and best practices in each domain.\\n\\t* Resources: Case studies, industry reports, and conferences.\\n\\n**Phase 5: Career Development and Continuous Learning**\\n\\n1. **Career Development**:\\n\\t* Network with professionals in the field.\\n\\t* Build a portfolio of projects and showcase your skills.\\n\\t* Prepare for common ML interview questions.\\n2. **Continuous Learning**:\\n\\t* Stay updated with the latest research and breakthroughs.\\n\\t* Participate in online communities: Kaggle, Reddit, and GitHub.\\n\\t* Attend conferences, meetups, and workshops.\\n\\n**Additional Tips**\\n\\n* Practice consistently and work on projects that interest you.\\n* Join online communities and forums to connect with other learners.\\n* Read research papers and books to deepen your understanding of ML concepts.\\n* Participate in competitions and hackathons to test your skills.\\n\\nBy following this roadmap, you'll be well on your way to becoming proficient in Machine Learning. Remember to stay curious, keep learning, and adapt to the ever-changing landscape of ML.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5q4DCnvSwqYm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}